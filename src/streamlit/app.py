import sys
import os
import streamlit as st
import pandas as pd

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# Caminhos dos arquivos
PREDICTIONS_FILE = "data/predictions.csv"
ITEMS_FILES = ["data/itens-parte1.csv", "data/itens-parte2.csv", "data/itens-parte3.csv"]

# Fun√ß√£o para carregar os t√≠tulos das not√≠cias
@st.cache_data
def load_news_items():
    news_df = pd.concat([pd.read_csv(f) for f in ITEMS_FILES])  # Carrega e junta os arquivos
    return news_df.set_index("page")  # Define "page" como √≠ndice para busca r√°pida

# Fun√ß√£o para carregar as recomenda√ß√µes
@st.cache_data
def load_predictions():
    pred_df = pd.read_csv(PREDICTIONS_FILE)
    pred_df["recommendations"] = pred_df["recommendations"].apply(eval)  # Converte string para lista
    return pred_df.set_index("userId")

# Carregar dados
news_data = load_news_items()
predictions = load_predictions()

# Interface Streamlit
st.title("üîç Recomenda√ß√£o de Not√≠cias")

# Entrada do usu√°rio
user_id = st.text_input("Digite um ID de usu√°rio:", "")

if st.button("Obter Recomenda√ß√µes"):
    if user_id.strip() == "":
        st.warning("‚ö†Ô∏è Por favor, insira um ID de usu√°rio.")
    elif user_id in predictions.index:
        recommended_news = predictions.loc[user_id, "recommendations"]

        st.subheader("üì¢ Not√≠cias Recomendadas:")
        for news_id in recommended_news:
            if news_id in news_data.index:
                title = news_data.loc[news_id, "title"]
                url = news_data.loc[news_id, "url"]
                st.markdown(f"üîπ **[{title}]({url})**")
            else:
                st.markdown(f"‚ö†Ô∏è Not√≠cia n√£o encontrada: `{news_id}`")
    else:
        st.warning("‚ö†Ô∏è Nenhuma recomenda√ß√£o encontrada para este usu√°rio.")
